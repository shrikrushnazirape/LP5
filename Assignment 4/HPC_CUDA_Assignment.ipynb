{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1XXHREWWfsg",
    "outputId": "0d12ee39-f1a1-480e-a7d2-0fe71e48d786"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
      "Cuda compilation tools, release 11.8, V11.8.89\n",
      "Build cuda_11.8.r11.8/compiler.31833905_0\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UQMRcRa0Xxa_",
    "outputId": "c044d51a-aa60-4b91-d919-359bfe60d48b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
      "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-xxi1lfcf\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-xxi1lfcf\n",
      "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: NVCCPlugin\n",
      "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4305 sha256=9ac0d74cfea2102bb7cc31936181f5e05a8109d6dd004495e636cb6b0f809d95\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-x7nzram1/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
      "Successfully built NVCCPlugin\n",
      "Installing collected packages: NVCCPlugin\n",
      "Successfully installed NVCCPlugin-0.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hRENpGO0ZGiU",
    "outputId": "365097f9-9bf3-472c-8ee1-2ec10911df7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created output directory at /content/src\n",
      "Out bin /content/result.out\n"
     ]
    }
   ],
   "source": [
    "%load_ext nvcc_plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 38
    },
    "id": "4ExqOLYNZtfe",
    "outputId": "75c8bb7b-829c-4e03-c868-106f766b8a4e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'File written in /content/src/vector_add.cu'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%cuda --name vector_add.cu\n",
    "#include<iostream>\n",
    "#include<bits/stdc++.h>\n",
    "#include<cuda.h>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "void fill_array(int *arr,int size){\n",
    "    for(int i = 0;i < size; i++){\n",
    "        arr[i] = rand() % 100;\n",
    "    }\n",
    "}\n",
    "\n",
    "void add_cpu(int *arr1, int *arr2, int *result, int size){\n",
    "    for(int i = 0;i < size; i++){\n",
    "        result[i] = arr1[i] + arr2[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "void print_matrix(int *arr, int size){\n",
    "    for(int i = 0; i < size; i++){\n",
    "        cout << arr[i] << \" \";\n",
    "    }\n",
    "    cout << endl;\n",
    "}\n",
    "\n",
    "__global__ void add(int *arr1, int *arr2, int *arr3){\n",
    "    int block_id = blockIdx.x;\n",
    "    arr3[block_id] = arr1[block_id] + arr2[block_id];\n",
    "}\n",
    "\n",
    "int main(){\n",
    "    int *arr1_cpu,*arr2_cpu,*result_cpu;\n",
    "    int size;\n",
    "    cout << \"Enter size of vector: \";\n",
    "    cin >> size;\n",
    "\n",
    "    arr1_cpu = new int[size];\n",
    "    arr2_cpu = new int[size];\n",
    "    result_cpu = new int[size];\n",
    "\n",
    "    fill_array(arr1_cpu,size);\n",
    "    cout << \"Array 1: \";\n",
    "    print_matrix(arr1_cpu,size);\n",
    "    fill_array(arr2_cpu,size);\n",
    "    cout << \"Array 2: \";\n",
    "    print_matrix(arr2_cpu,size);\n",
    "\n",
    "    int *arr1_gpu,*arr2_gpu,*result_gpu;\n",
    "    \n",
    "    cudaMallocManaged(&arr1_gpu, size * sizeof(int));\n",
    "    cudaMallocManaged(&arr2_gpu, size * sizeof(int));\n",
    "    cudaMallocManaged(&result_gpu, size * sizeof(int));\n",
    "\n",
    "    cudaMemcpy(arr1_gpu,arr1_cpu,size * sizeof(int),cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(arr2_gpu,arr2_cpu,size * sizeof(int),cudaMemcpyHostToDevice);\n",
    "    cudaEvent_t start,stop;\n",
    "    float elapsedTime;\n",
    "\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    cudaEventRecord(start,0);\n",
    "\n",
    "    add<<<size,1>>>(arr1_gpu,arr2_gpu,result_gpu);\n",
    "    cudaEventRecord(stop,0);\n",
    "    cudaEventSynchronize(stop);\n",
    "    cudaEventElapsedTime(&elapsedTime,start,stop);\n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "    cudaMemcpy(result_cpu,result_gpu,size * sizeof(int),cudaMemcpyDeviceToHost);\n",
    "    cout << \"GPU result:\\n\";\n",
    "    print_matrix(result_cpu,size);\n",
    "    cout<<\"Elapsed Time = \"<<elapsedTime<<\" milliseconds\" << endl;\n",
    "    cudaFree(arr1_gpu);\n",
    "    cudaFree(arr2_gpu);\n",
    "    cudaFree(result_gpu);\n",
    "\n",
    "    cudaEventCreate(&start);\n",
    "    cudaEventCreate(&stop);\n",
    "    cudaEventRecord(start,0);\n",
    "\n",
    "    add_cpu(arr1_cpu,arr2_cpu,result_cpu,size);\n",
    "    cudaEventRecord(stop,0);\n",
    "    cudaEventSynchronize(stop);\n",
    "    cudaEventElapsedTime(&elapsedTime,start,stop);\n",
    "    cudaEventDestroy(start);\n",
    "    cudaEventDestroy(stop);\n",
    "    cout << \"CPU result:\\n\";\n",
    "    print_matrix(result_cpu,size);\n",
    "    cout<<\"Elapsed Time = \"<<elapsedTime<<\" milliseconds\" << endl;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DLecw_AJamEY"
   },
   "outputs": [],
   "source": [
    "!nvcc /content/src/vector_add.cu -o /content/src/vector_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oRnx20HcawRI",
    "outputId": "6f502747-948a-409e-fe52-c98e454e5e7f"
   },
   "outputs": [],
   "source": [
    "!/content/src/vector_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 38
    },
    "id": "9ypLYwrTa1EF",
    "outputId": "8671aa13-df32-46b8-cdbb-e1af482915df"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'File written in /content/src/matrix_multiply.cu'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%cuda --name matrix_multiply.cu\n",
    "#include<iostream>\n",
    "#include<bits/stdc++.h>\n",
    "#include<cuda.h>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "void initialize_matrix(int *array, int rows, int cols){\n",
    "    for(int i = 0 ; i < rows; i++){\n",
    "        for(int j = 0; j < cols; j++){\n",
    "            array[i*cols + j] = rand() % 10;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "void print_matrix(int *array, int rows, int cols){\n",
    "    for(int i = 0 ; i < rows; i++){\n",
    "        for(int j = 0; j < cols; j++){\n",
    "            cout << array[i*cols + j] << \" \";\n",
    "        }\n",
    "        cout << endl;\n",
    "    }\n",
    "}\n",
    "\n",
    "void matrix_multiplication_cpu(int *a, int *b, int *c, int common, int c_rows,int c_cols){\n",
    "    for(int i = 0; i < c_rows; i++){\n",
    "        for(int j = 0; j < c_cols; j++){\n",
    "            int sum = 0;\n",
    "            for(int k = 0; k < common; k++){\n",
    "                sum += a[i*common + k] * b[k*c_cols + j];\n",
    "            }\n",
    "            c[i*c_cols + j] = sum;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "__global__\n",
    "void matrix_multiply(int *a, int *b, int *c, int m, int n, int k)\n",
    "{\n",
    "    int row = blockIdx.y*blockDim.y + threadIdx.y;\n",
    "    int col = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "    int sum=0;\n",
    "   \n",
    "    if(col<k && row<m) {\n",
    "      for(int j=0;j<n;j++)\n",
    "      {\n",
    "          sum += a[row*n+j] * b[j*k+col];\n",
    "      }\n",
    "      c[k*row+col]=sum;\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "int main(){\n",
    "\n",
    "    int A_rows, A_cols, B_rows, B_cols, C_rows, C_cols;\n",
    "    cout << \"Dimensions of matrix 1:\\n\";\n",
    "    cout << \"Rows: \";\n",
    "    cin >> A_rows;\n",
    "    cout << \"Columns: \";\n",
    "    cin >> A_cols;\n",
    "    cout << \"Dimensions of matrix 2:\\n\";\n",
    "    cout << \"Rows: \" << A_cols << endl << \"Columns: \";\n",
    "    cin >> B_cols;\n",
    "    B_rows = A_cols;\n",
    "    C_rows = A_rows;\n",
    "    C_cols = B_cols;\n",
    "\n",
    "    int A_size = A_rows * A_cols;\n",
    "    int B_size = B_rows * B_cols;\n",
    "    int C_size = C_rows * C_cols;\n",
    "\n",
    "    int *A, *B, *C;\n",
    "    int *m1,*m2,*result;\n",
    "\n",
    "    A = new int[A_size];\n",
    "    B = new int[B_size];\n",
    "    C = new int[C_size];\n",
    "\n",
    "    initialize_matrix(A,A_rows,A_cols);\n",
    "    cout << \"Matrix 1\\n\";\n",
    "    print_matrix(A,A_rows,A_cols);\n",
    "    initialize_matrix(B,B_rows,B_cols);\n",
    "    cout << \"Matrix 2\\n\";\n",
    "    print_matrix(B,B_rows,B_cols);\n",
    "\n",
    "    cudaMallocManaged(&m1, A_size * sizeof(int));\n",
    "    cudaMallocManaged(&m2, B_size * sizeof(int));\n",
    "    cudaMallocManaged(&result, C_size * sizeof(int));\n",
    "\n",
    "    cudaMemcpy(m1,A,A_size * sizeof(int), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(m2,B,B_size * sizeof(int), cudaMemcpyHostToDevice);\n",
    "\n",
    "    dim3 dimGrid(2,2);\n",
    "    dim3 dimBlock(C_rows,C_cols);\n",
    "\n",
    "    float gpu_elapsed_time;\n",
    "    cudaEvent_t gpu_start,gpu_stop;\n",
    "\n",
    "    cudaEventCreate(&gpu_start);\n",
    "    cudaEventCreate(&gpu_stop);\n",
    "    cudaEventRecord(gpu_start);\n",
    "    matrix_multiply<<<dimGrid,dimBlock>>>(m1,m2,result,C_rows,A_cols,C_cols);\n",
    "    cudaEventRecord(gpu_stop);\n",
    "    cudaEventSynchronize(gpu_stop);\n",
    "    cudaEventElapsedTime(&gpu_elapsed_time, gpu_start, gpu_stop);\n",
    "    cudaEventDestroy(gpu_start);\n",
    "    cudaEventDestroy(gpu_stop);\n",
    "\n",
    "    cudaMemcpy(C,result,C_size*sizeof(int),cudaMemcpyDeviceToHost);\n",
    "    cout << \"GPU result:\\n\";\n",
    "    print_matrix(C,C_rows,C_cols);\n",
    "    cout<<\"GPU Elapsed time is: \"<<gpu_elapsed_time<<\" milliseconds\"<<endl;\n",
    "\n",
    "    cudaEventCreate(&gpu_start);\n",
    "    cudaEventCreate(&gpu_stop);\n",
    "    cudaEventRecord(gpu_start);\n",
    "    matrix_multiplication_cpu(A,B,C,A_cols,C_rows,C_cols);\n",
    "    cudaEventRecord(gpu_stop);\n",
    "    cudaEventSynchronize(gpu_stop);\n",
    "    cudaEventElapsedTime(&gpu_elapsed_time, gpu_start, gpu_stop);\n",
    "    cudaEventDestroy(gpu_start);\n",
    "    cudaEventDestroy(gpu_stop);\n",
    "\n",
    "    cout << \"CPU result:\\n\";\n",
    "    print_matrix(C,C_rows,C_cols);\n",
    "    cout<<\"CPU Elapsed time is: \"<<gpu_elapsed_time<<\" milliseconds\"<<endl;\n",
    "\n",
    "    cudaFree(m1);\n",
    "    cudaFree(m2);\n",
    "    cudaFree(result);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "t6NYJo5VMfEr"
   },
   "outputs": [],
   "source": [
    "!nvcc /content/src/matrix_multiply.cu -o /content/src/matrix_multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KATF5dtXMwgL",
    "outputId": "ca131c4f-81df-4853-eaae-e1a2db8c7c47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of matrix 1:\n",
      "Rows: 10\n",
      "Columns: 8\n",
      "Dimensions of matrix 2:\n",
      "Rows: 8\n",
      "Columns: 12\n",
      "Matrix 1\n",
      "3 6 7 5 3 5 6 2 \n",
      "9 1 2 7 0 9 3 6 \n",
      "0 6 2 6 1 8 7 9 \n",
      "2 0 2 3 7 5 9 2 \n",
      "2 8 9 7 3 6 1 2 \n",
      "9 3 1 9 4 7 8 4 \n",
      "5 0 3 6 1 0 6 3 \n",
      "2 0 6 1 5 5 4 7 \n",
      "6 5 6 9 3 7 4 5 \n",
      "2 5 4 7 4 4 3 0 \n",
      "Matrix 2\n",
      "7 8 6 8 8 4 3 1 4 9 2 0 \n",
      "6 8 9 2 6 6 4 9 5 0 4 8 \n",
      "7 1 7 2 7 2 2 6 1 0 6 1 \n",
      "5 9 4 9 0 9 1 7 7 1 1 5 \n",
      "9 7 7 6 7 3 6 5 6 3 9 4 \n",
      "8 1 2 9 3 9 0 8 8 5 0 9 \n",
      "6 3 8 5 6 1 1 5 9 8 4 8 \n",
      "1 0 3 0 4 4 4 4 7 6 3 1 \n",
      "GPU result:\n",
      "236 168 226 188 189 175 84 227 210 126 134 187 \n",
      "214 163 165 237 161 217 69 190 233 193 71 156 \n",
      "204 140 198 183 159 212 83 248 270 159 106 221 \n",
      "202 126 175 179 156 122 72 163 208 151 124 164 \n",
      "243 182 222 190 180 209 90 253 195 84 134 184 \n",
      "277 237 242 288 210 236 98 237 295 225 125 217 \n",
      "134 122 139 136 116 101 51 112 146 120 76 88 \n",
      "177 83 156 132 160 121 81 158 176 133 123 115 \n",
      "271 215 241 252 206 243 101 261 263 169 135 203 \n",
      "193 164 173 172 132 160 68 187 169 81 103 155 \n",
      "GPU Elapsed time is: 0.01104 milliseconds\n",
      "CPU result:\n",
      "236 168 226 188 189 175 84 227 210 126 134 187 \n",
      "214 163 165 237 161 217 69 190 233 193 71 156 \n",
      "204 140 198 183 159 212 83 248 270 159 106 221 \n",
      "202 126 175 179 156 122 72 163 208 151 124 164 \n",
      "243 182 222 190 180 209 90 253 195 84 134 184 \n",
      "277 237 242 288 210 236 98 237 295 225 125 217 \n",
      "134 122 139 136 116 101 51 112 146 120 76 88 \n",
      "177 83 156 132 160 121 81 158 176 133 123 115 \n",
      "271 215 241 252 206 243 101 261 263 169 135 203 \n",
      "193 164 173 172 132 160 68 187 169 81 103 155 \n",
      "CPU Elapsed time is: 0.007648 milliseconds\n"
     ]
    }
   ],
   "source": [
    "!/content/src/matrix_multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "SAu53_m4Ne0n"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
